"use strict";(globalThis.webpackChunkrobotics_book=globalThis.webpackChunkrobotics_book||[]).push([[782],{2292:(e,n,a)=>{a.r(n),a.d(n,{assets:()=>c,contentTitle:()=>l,default:()=>m,frontMatter:()=>r,metadata:()=>s,toc:()=>d});const s=JSON.parse('{"id":"chapter4/lesson2/hardware-accelerated-navigation","title":"hardware-accelerated-navigation","description":"In this comprehensive lesson, you\'ll explore NVIDIA Isaac ROS, a collection of hardware-accelerated perception and navigation packages designed specifically for robotics applications. Isaac ROS leverages NVIDIA\'s GPU computing capabilities to accelerate critical navigation tasks for humanoid robots, enabling real-time performance for complex algorithms.","source":"@site/docs/chapter4/lesson2/hardware-accelerated-navigation.mdx","sourceDirName":"chapter4/lesson2","slug":"/chapter4/lesson2/hardware-accelerated-navigation","permalink":"/humanoid_robotic_book/docs/chapter4/lesson2/hardware-accelerated-navigation","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"sidebar_position":1},"sidebar":"mySidebar","previous":{"title":"isaac-sim-synthetic-data","permalink":"/humanoid_robotic_book/docs/chapter4/lesson1/isaac-sim-synthetic-data"},"next":{"title":"bipedal-path-planning","permalink":"/humanoid_robotic_book/docs/chapter4/lesson3/bipedal-path-planning"}}');var i=a(4848),t=a(8453),o=a(5959);const r={sidebar_position:1},l="Hardware-Accelerated Navigation (Isaac ROS)",c={},d=[{value:"Introduction to Isaac ROS",id:"introduction-to-isaac-ros",level:2},{value:"Key Components of Isaac ROS",id:"key-components-of-isaac-ros",level:3},{value:"Isaac ROS Installation and Setup",id:"isaac-ros-installation-and-setup",level:2},{value:"System Requirements",id:"system-requirements",level:3},{value:"Installation Methods",id:"installation-methods",level:3},{value:"Method 1: Docker Installation (Recommended)",id:"method-1-docker-installation-recommended",level:4},{value:"Method 2: APT Package Installation",id:"method-2-apt-package-installation",level:4},{value:"Method 3: Source Installation",id:"method-3-source-installation",level:4},{value:"Isaac ROS Image Pipeline",id:"isaac-ros-image-pipeline",level:2},{value:"Hardware-Accelerated Image Processing",id:"hardware-accelerated-image-processing",level:3},{value:"Isaac ROS Stereo Dense Reconstruction",id:"isaac-ros-stereo-dense-reconstruction",level:3},{value:"Isaac ROS SLAM Implementation",id:"isaac-ros-slam-implementation",level:2},{value:"Visual-Inertial SLAM",id:"visual-inertial-slam",level:3},{value:"Isaac ROS Navigation Stack",id:"isaac-ros-navigation-stack",level:2},{value:"Hardware-Accelerated Path Planning",id:"hardware-accelerated-path-planning",level:3},{value:"Isaac ROS Object Detection and Perception",id:"isaac-ros-object-detection-and-perception",level:2},{value:"Hardware-Accelerated Object Detection",id:"hardware-accelerated-object-detection",level:3},{value:"Integration with Humanoid Robot Navigation",id:"integration-with-humanoid-robot-navigation",level:2},{value:"Complete Navigation Pipeline",id:"complete-navigation-pipeline",level:3},{value:"Performance Optimization",id:"performance-optimization",level:2},{value:"GPU Memory Management",id:"gpu-memory-management",level:3},{value:"Best Practices for Isaac ROS",id:"best-practices-for-isaac-ros",level:2},{value:"1. Hardware Optimization",id:"1-hardware-optimization",level:3},{value:"2. Pipeline Design",id:"2-pipeline-design",level:3},{value:"3. Performance Monitoring",id:"3-performance-monitoring",level:3},{value:"4. Integration Considerations",id:"4-integration-considerations",level:3},{value:"Troubleshooting Common Issues",id:"troubleshooting-common-issues",level:2},{value:"1. GPU Memory Issues",id:"1-gpu-memory-issues",level:3},{value:"2. Performance Optimization",id:"2-performance-optimization",level:3},{value:"3. Compatibility Issues",id:"3-compatibility-issues",level:3},{value:"Hands-on Exercise",id:"hands-on-exercise",level:2},{value:"Quiz Questions",id:"quiz-questions",level:2}];function p(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,t.R)(),...e.components};return(0,i.jsxs)(o.A,{title:"Hardware-Accelerated Navigation (Isaac ROS)",chapter:4,lesson:2,children:[(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"hardware-accelerated-navigation-isaac-ros",children:"Hardware-Accelerated Navigation (Isaac ROS)"})}),(0,i.jsx)(n.p,{children:"In this comprehensive lesson, you'll explore NVIDIA Isaac ROS, a collection of hardware-accelerated perception and navigation packages designed specifically for robotics applications. Isaac ROS leverages NVIDIA's GPU computing capabilities to accelerate critical navigation tasks for humanoid robots, enabling real-time performance for complex algorithms."}),(0,i.jsx)(n.h2,{id:"introduction-to-isaac-ros",children:"Introduction to Isaac ROS"}),(0,i.jsx)(n.p,{children:"NVIDIA Isaac ROS is a collection of GPU-accelerated perception and navigation packages that provide:"}),(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Hardware Acceleration"}),": GPU-accelerated algorithms for real-time performance"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Perception"}),": Advanced computer vision and sensor processing"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Navigation"}),": SLAM, path planning, and motion control"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Integration"}),": Seamless integration with ROS 2 ecosystem"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Optimization"}),": Performance optimized for NVIDIA hardware"]}),"\n"]}),(0,i.jsx)(n.h3,{id:"key-components-of-isaac-ros",children:"Key Components of Isaac ROS"}),(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Isaac ROS Image Pipeline"}),": Hardware-accelerated image processing"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Isaac ROS Stereo Dense Reconstruction"}),": 3D scene reconstruction"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Isaac ROS Object Detection"}),": AI-powered object detection"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Isaac ROS SLAM"}),": Simultaneous Localization and Mapping"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Isaac ROS Navigation"}),": Path planning and motion control"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Isaac ROS Manipulation"}),": Advanced manipulation algorithms"]}),"\n"]}),(0,i.jsx)(n.h2,{id:"isaac-ros-installation-and-setup",children:"Isaac ROS Installation and Setup"}),(0,i.jsx)(n.h3,{id:"system-requirements",children:"System Requirements"}),(0,i.jsx)(n.p,{children:"Before installing Isaac ROS, ensure your system meets these requirements:"}),(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"GPU"}),": NVIDIA GPU with CUDA compute capability 6.0+ (Pascal architecture or newer)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"VRAM"}),": 8GB+ (16GB+ recommended for complex processing)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"CUDA"}),": CUDA 11.8+ with compatible drivers"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"OS"}),": Ubuntu 20.04/22.04 LTS"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"ROS 2"}),": Humble Hawksbill or newer"]}),"\n"]}),(0,i.jsx)(n.h3,{id:"installation-methods",children:"Installation Methods"}),(0,i.jsx)(n.h4,{id:"method-1-docker-installation-recommended",children:"Method 1: Docker Installation (Recommended)"}),(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:'# Pull Isaac ROS Docker image\ndocker pull nvcr.io/nvidia/isaac-ros:latest\n\n# Run Isaac ROS container\ndocker run --gpus all -it --rm \\\n  --network=host \\\n  --env "DISPLAY" \\\n  --volume="/tmp/.X11-unix:/tmp/.X11-unix:rw" \\\n  --volume="/home/$USER/.Xauthority:/root/.Xauthority:rw" \\\n  --volume="/home/$USER/isaac_ros_workspace:/workspace" \\\n  --privileged \\\n  nvcr.io/nvidia/isaac-ros:latest\n'})}),(0,i.jsx)(n.h4,{id:"method-2-apt-package-installation",children:"Method 2: APT Package Installation"}),(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:'# Add NVIDIA package repository\ncurl -sSL https://repos.mapd.com/apt/mapd-deps.pub | sudo apt-key add -\nsudo add-apt-repository "deb https://repos.mapd.com/ubuntu $(lsb_release -cs)-mapd-deps main"\n\n# Update package lists\nsudo apt update\n\n# Install Isaac ROS packages\nsudo apt install ros-humble-isaac-ros-common\nsudo apt install ros-humble-isaac-ros-image-pipeline\nsudo apt install ros-humble-isaac-ros-slam\nsudo apt install ros-humble-isaac-ros-navigation\n'})}),(0,i.jsx)(n.h4,{id:"method-3-source-installation",children:"Method 3: Source Installation"}),(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# Create ROS workspace\nmkdir -p ~/isaac_ros_ws/src\ncd ~/isaac_ros_ws\n\n# Clone Isaac ROS repositories\ngit clone https://github.com/NVIDIA-ISAAC-ROS/isaac_ros_common.git src/isaac_ros_common\ngit clone https://github.com/NVIDIA-ISAAC-ROS/isaac_ros_image_pipeline.git src/isaac_ros_image_pipeline\ngit clone https://github.com/NVIDIA-ISAAC-ROS/isaac_ros_visual_slam.git src/isaac_ros_visual_slam\ngit clone https://github.com/NVIDIA-ISAAC-ROS/isaac_ros_nav2_bringup.git src/isaac_ros_nav2_bringup\n\n# Install dependencies\nrosdep install --from-paths src --ignore-src -r -y\n\n# Build packages\ncolcon build --packages-select isaac_ros_common isaac_ros_image_pipeline isaac_ros_visual_slam\n"})}),(0,i.jsx)(n.h2,{id:"isaac-ros-image-pipeline",children:"Isaac ROS Image Pipeline"}),(0,i.jsx)(n.h3,{id:"hardware-accelerated-image-processing",children:"Hardware-Accelerated Image Processing"}),(0,i.jsx)(n.p,{children:"The Isaac ROS Image Pipeline provides GPU-accelerated image processing capabilities:"}),(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'import rclpy\nfrom rclpy.node import Node\nfrom sensor_msgs.msg import Image\nfrom cv_bridge import CvBridge\nimport cv2\nimport numpy as np\n\nclass IsaacROSImageProcessor(Node):\n    def __init__(self):\n        super().__init__(\'isaac_ros_image_processor\')\n\n        # Create subscription for camera images\n        self.image_sub = self.create_subscription(\n            Image, \'/camera/image_raw\', self.image_callback, 10)\n\n        # Create publisher for processed images\n        self.processed_pub = self.create_publisher(\n            Image, \'/camera/image_processed\', 10)\n\n        self.bridge = CvBridge()\n\n        # Initialize GPU-accelerated processing\n        self.setup_gpu_processing()\n\n    def setup_gpu_processing(self):\n        """Initialize GPU-accelerated image processing"""\n        # This would typically involve:\n        # - Initializing CUDA contexts\n        # - Setting up GPU memory pools\n        # - Configuring hardware-accelerated codecs\n        pass\n\n    def image_callback(self, msg):\n        """Process incoming image with GPU acceleration"""\n        try:\n            # Convert ROS image to OpenCV format\n            cv_image = self.bridge.imgmsg_to_cv2(msg, desired_encoding=\'bgr8\')\n\n            # Perform GPU-accelerated processing\n            processed_image = self.gpu_process_image(cv_image)\n\n            # Convert back to ROS image format\n            processed_msg = self.bridge.cv2_to_imgmsg(processed_image, encoding=\'bgr8\')\n            processed_msg.header = msg.header\n\n            # Publish processed image\n            self.processed_pub.publish(processed_msg)\n\n        except Exception as e:\n            self.get_logger().error(f\'Error processing image: {e}\')\n\n    def gpu_process_image(self, image):\n        """GPU-accelerated image processing"""\n        # This would use Isaac ROS hardware-accelerated functions\n        # such as:\n        # - Hardware-accelerated color conversion\n        # - GPU-based filtering and enhancement\n        # - Accelerated feature detection\n\n        # Placeholder for GPU processing\n        return image\n\ndef main(args=None):\n    rclpy.init(args=args)\n    processor = IsaacROSImageProcessor()\n\n    try:\n        rclpy.spin(processor)\n    except KeyboardInterrupt:\n        processor.get_logger().info(\'Shutting down\')\n    finally:\n        processor.destroy_node()\n        rclpy.shutdown()\n\nif __name__ == \'__main__\':\n    main()\n'})}),(0,i.jsx)(n.h3,{id:"isaac-ros-stereo-dense-reconstruction",children:"Isaac ROS Stereo Dense Reconstruction"}),(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'import rclpy\nfrom rclpy.node import Node\nfrom sensor_msgs.msg import Image\nfrom stereo_msgs.msg import DisparityImage\nfrom sensor_msgs.msg import PointCloud2\nimport numpy as np\n\nclass IsaacROSDenseReconstruction(Node):\n    def __init__(self):\n        super().__init__(\'isaac_ros_dense_reconstruction\')\n\n        # Subscriptions for stereo images\n        self.left_sub = self.create_subscription(\n            Image, \'/stereo/left/image_rect\', self.left_image_callback, 10)\n        self.right_sub = self.create_subscription(\n            Image, \'/stereo/right/image_rect\', self.right_image_callback, 10)\n\n        # Publishers for disparity and point cloud\n        self.disparity_pub = self.create_publisher(\n            DisparityImage, \'/stereo/disparity\', 10)\n        self.pointcloud_pub = self.create_publisher(\n            PointCloud2, \'/stereo/pointcloud\', 10)\n\n        # Store stereo images\n        self.left_image = None\n        self.right_image = None\n\n        # Initialize GPU-accelerated stereo processing\n        self.setup_gpu_stereo()\n\n    def setup_gpu_stereo(self):\n        """Initialize GPU-accelerated stereo processing"""\n        # Configure GPU-based stereo matching algorithm\n        # This would typically use CUDA-optimized stereo algorithms\n        pass\n\n    def left_image_callback(self, msg):\n        """Handle left stereo image"""\n        self.left_image = msg\n        if self.right_image is not None:\n            self.process_stereo_pair()\n\n    def right_image_callback(self, msg):\n        """Handle right stereo image"""\n        self.right_image = msg\n        if self.left_image is not None:\n            self.process_stereo_pair()\n\n    def process_stereo_pair(self):\n        """Process stereo image pair to generate disparity and point cloud"""\n        # This would use Isaac ROS hardware-accelerated stereo processing\n        # to generate disparity maps and 3D point clouds\n        pass\n\ndef main(args=None):\n    rclpy.init(args=args)\n    reconstruction = IsaacROSDenseReconstruction()\n\n    try:\n        rclpy.spin(reconstruction)\n    except KeyboardInterrupt:\n        reconstruction.get_logger().info(\'Shutting down\')\n    finally:\n        reconstruction.destroy_node()\n        rclpy.shutdown()\n\nif __name__ == \'__main__\':\n    main()\n'})}),(0,i.jsx)(n.h2,{id:"isaac-ros-slam-implementation",children:"Isaac ROS SLAM Implementation"}),(0,i.jsx)(n.h3,{id:"visual-inertial-slam",children:"Visual-Inertial SLAM"}),(0,i.jsx)(n.p,{children:"Isaac ROS provides hardware-accelerated Visual-Inertial SLAM (VSLAM):"}),(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'import rclpy\nfrom rclpy.node import Node\nfrom sensor_msgs.msg import Image, Imu\nfrom geometry_msgs.msg import PoseStamped\nfrom nav_msgs.msg import Odometry\nimport numpy as np\n\nclass IsaacROSVisualSLAM(Node):\n    def __init__(self):\n        super().__init__(\'isaac_ros_visual_slam\')\n\n        # Subscriptions for camera and IMU data\n        self.image_sub = self.create_subscription(\n            Image, \'/camera/image_raw\', self.image_callback, 10)\n        self.imu_sub = self.create_subscription(\n            Imu, \'/imu/data\', self.imu_callback, 10)\n\n        # Publishers for pose and map\n        self.pose_pub = self.create_publisher(\n            PoseStamped, \'/visual_slam/pose\', 10)\n        self.odom_pub = self.create_publisher(\n            Odometry, \'/visual_slam/odometry\', 10)\n\n        # Initialize GPU-accelerated VSLAM\n        self.setup_gpu_vslam()\n\n        # Tracking variables\n        self.imu_data_buffer = []\n        self.current_pose = np.eye(4)  # 4x4 transformation matrix\n\n    def setup_gpu_vslam(self):\n        """Initialize GPU-accelerated Visual SLAM"""\n        # Configure hardware-accelerated feature detection\n        # Set up GPU memory for tracking and mapping\n        # Initialize CUDA-based optimization routines\n        pass\n\n    def image_callback(self, msg):\n        """Process camera image for visual SLAM"""\n        # Extract features using GPU acceleration\n        features = self.extract_gpu_features(msg)\n\n        # Track features and update pose\n        if len(self.imu_data_buffer) > 0:\n            pose_update = self.track_features_and_update_pose(\n                features, self.imu_data_buffer)\n            self.current_pose = self.update_pose(\n                self.current_pose, pose_update)\n\n            # Publish updated pose\n            self.publish_pose()\n\n    def imu_callback(self, msg):\n        """Process IMU data for inertial integration"""\n        # Store IMU data for fusion with visual data\n        imu_data = {\n            \'angular_velocity\': [\n                msg.angular_velocity.x,\n                msg.angular_velocity.y,\n                msg.angular_velocity.z\n            ],\n            \'linear_acceleration\': [\n                msg.linear_acceleration.x,\n                msg.linear_acceleration.y,\n                msg.linear_acceleration.z\n            ],\n            \'timestamp\': msg.header.stamp\n        }\n        self.imu_data_buffer.append(imu_data)\n\n    def extract_gpu_features(self, image_msg):\n        """Extract features using GPU acceleration"""\n        # This would use Isaac ROS hardware-accelerated feature detection\n        # such as ORB, SIFT, or other feature detectors optimized for GPU\n        pass\n\n    def track_features_and_update_pose(self, features, imu_buffer):\n        """Track features and compute pose update"""\n        # Perform GPU-accelerated feature tracking\n        # Fuse visual and inertial data\n        # Compute pose update\n        pass\n\n    def update_pose(self, current_pose, pose_update):\n        """Update current pose with new transformation"""\n        return np.dot(current_pose, pose_update)\n\n    def publish_pose(self):\n        """Publish current pose estimate"""\n        pose_msg = PoseStamped()\n        pose_msg.header.stamp = self.get_clock().now().to_msg()\n        pose_msg.header.frame_id = \'map\'\n\n        # Convert transformation matrix to pose\n        pose_msg.pose.position.x = self.current_pose[0, 3]\n        pose_msg.pose.position.y = self.current_pose[1, 3]\n        pose_msg.pose.position.z = self.current_pose[2, 3]\n\n        # Convert rotation matrix to quaternion\n        # (simplified - in practice would use proper conversion)\n        pose_msg.pose.orientation.w = 1.0  # Placeholder\n\n        self.pose_pub.publish(pose_msg)\n\ndef main(args=None):\n    rclpy.init(args=args)\n    slam = IsaacROSVisualSLAM()\n\n    try:\n        rclpy.spin(slam)\n    except KeyboardInterrupt:\n        slam.get_logger().info(\'Shutting down\')\n    finally:\n        slam.destroy_node()\n        rclpy.shutdown()\n\nif __name__ == \'__main__\':\n    main()\n'})}),(0,i.jsx)(n.h2,{id:"isaac-ros-navigation-stack",children:"Isaac ROS Navigation Stack"}),(0,i.jsx)(n.h3,{id:"hardware-accelerated-path-planning",children:"Hardware-Accelerated Path Planning"}),(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'import rclpy\nfrom rclpy.node import Node\nfrom geometry_msgs.msg import PoseStamped, Point\nfrom nav_msgs.msg import Path, OccupancyGrid\nfrom visualization_msgs.msg import MarkerArray\nimport numpy as np\nfrom scipy.spatial import KDTree\n\nclass IsaacROSPathPlanner(Node):\n    def __init__(self):\n        super().__init__(\'isaac_ros_path_planner\')\n\n        # Subscriptions\n        self.map_sub = self.create_subscription(\n            OccupancyGrid, \'/map\', self.map_callback, 10)\n        self.goal_sub = self.create_subscription(\n            PoseStamped, \'/move_base_simple/goal\', self.goal_callback, 10)\n\n        # Publishers\n        self.path_pub = self.create_publisher(\n            Path, \'/plan\', 10)\n        self.visualization_pub = self.create_publisher(\n            MarkerArray, \'/path_visualization\', 10)\n\n        # Initialize GPU-accelerated planning\n        self.setup_gpu_planning()\n\n        # Map and planning data\n        self.map_data = None\n        self.map_resolution = 0.05\n        self.map_origin = [0, 0, 0]\n\n    def setup_gpu_planning(self):\n        """Initialize GPU-accelerated path planning"""\n        # Configure GPU-based path planning algorithms\n        # Set up CUDA-optimized graph search routines\n        # Initialize GPU memory for planning operations\n        pass\n\n    def map_callback(self, msg):\n        """Process occupancy grid map"""\n        self.map_data = np.array(msg.data).reshape(\n            msg.info.height, msg.info.width)\n        self.map_resolution = msg.info.resolution\n        self.map_origin = [\n            msg.info.origin.position.x,\n            msg.info.origin.position.y,\n            msg.info.origin.orientation.z\n        ]\n\n    def goal_callback(self, msg):\n        """Process navigation goal and plan path"""\n        if self.map_data is None:\n            self.get_logger().warn(\'Map not received yet\')\n            return\n\n        # Convert goal to map coordinates\n        goal_x = int((msg.pose.position.x - self.map_origin[0]) / self.map_resolution)\n        goal_y = int((msg.pose.position.y - self.map_origin[1]) / self.map_resolution)\n\n        # Get current robot position (in a real implementation, this would come from localization)\n        current_x = int((-self.map_origin[0]) / self.map_resolution)  # Assuming robot starts at origin\n        current_y = int((-self.map_origin[1]) / self.map_resolution)\n\n        # Plan path using GPU acceleration\n        path = self.plan_gpu_path(current_x, current_y, goal_x, goal_y)\n\n        if path is not None:\n            self.publish_path(path)\n\n    def plan_gpu_path(self, start_x, start_y, goal_x, goal_y):\n        """Plan path using GPU acceleration"""\n        # This would use Isaac ROS hardware-accelerated path planning\n        # such as GPU-optimized A* or Dijkstra\'s algorithm\n\n        # Placeholder implementation\n        # In practice, this would leverage CUDA for:\n        # - Parallel graph search\n        # - Cost map computation\n        # - Path optimization\n\n        # Simple A* implementation (GPU-optimized version would be much faster)\n        try:\n            # Check if start and goal are valid\n            if (start_x < 0 or start_x >= self.map_data.shape[1] or\n                start_y < 0 or start_y >= self.map_data.shape[0] or\n                goal_x < 0 or goal_x >= self.map_data.shape[1] or\n                goal_y < 0 or goal_y >= self.map_data.shape[0]):\n                return None\n\n            # Check if start or goal are obstacles\n            if self.map_data[start_y, start_x] > 50 or self.map_data[goal_y, goal_x] > 50:\n                return None\n\n            # For this example, return a simple straight-line path\n            # A real GPU-accelerated implementation would be much more sophisticated\n            path = self.simple_gpu_pathfinding(start_x, start_y, goal_x, goal_y)\n            return path\n\n        except Exception as e:\n            self.get_logger().error(f\'Error in path planning: {e}\')\n            return None\n\n    def simple_gpu_pathfinding(self, start_x, start_y, goal_x, goal_y):\n        """Simple pathfinding (placeholder for GPU implementation)"""\n        # This would be replaced with a GPU-accelerated algorithm\n        # For demonstration, we\'ll return a simple path\n        path = []\n\n        # Simple line drawing algorithm\n        dx = goal_x - start_x\n        dy = goal_y - start_y\n        steps = max(abs(dx), abs(dy))\n\n        for i in range(steps + 1):\n            x = start_x + int(i * dx / steps)\n            y = start_y + int(i * dy / steps)\n            path.append((x, y))\n\n        return path\n\n    def publish_path(self, path):\n        """Publish planned path"""\n        path_msg = Path()\n        path_msg.header.stamp = self.get_clock().now().to_msg()\n        path_msg.header.frame_id = \'map\'\n\n        for x, y in path:\n            pose = PoseStamped()\n            pose.header.stamp = self.get_clock().now().to_msg()\n            pose.header.frame_id = \'map\'\n            pose.pose.position.x = x * self.map_resolution + self.map_origin[0]\n            pose.pose.position.y = y * self.map_resolution + self.map_origin[1]\n            pose.pose.position.z = 0.0\n            pose.pose.orientation.w = 1.0\n\n            path_msg.poses.append(pose)\n\n        self.path_pub.publish(path_msg)\n\ndef main(args=None):\n    rclpy.init(args=args)\n    planner = IsaacROSPathPlanner()\n\n    try:\n        rclpy.spin(planner)\n    except KeyboardInterrupt:\n        planner.get_logger().info(\'Shutting down\')\n    finally:\n        planner.destroy_node()\n        rclpy.shutdown()\n\nif __name__ == \'__main__\':\n    main()\n'})}),(0,i.jsx)(n.h2,{id:"isaac-ros-object-detection-and-perception",children:"Isaac ROS Object Detection and Perception"}),(0,i.jsx)(n.h3,{id:"hardware-accelerated-object-detection",children:"Hardware-Accelerated Object Detection"}),(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"import rclpy\nfrom rclpy.node import Node\nfrom sensor_msgs.msg import Image\nfrom vision_msgs.msg import Detection2DArray, ObjectHypothesisWithPose\nfrom cv_bridge import CvBridge\nimport numpy as np\n\nclass IsaacROSObjectDetector(Node):\n    def __init__(self):\n        super().__init__('isaac_ros_object_detector')\n\n        # Subscription for camera images\n        self.image_sub = self.create_subscription(\n            Image, '/camera/image_raw', self.image_callback, 10)\n\n        # Publisher for object detections\n        self.detection_pub = self.create_publisher(\n            Detection2DArray, '/object_detections', 10)\n\n        self.bridge = CvBridge()\n\n        # Initialize GPU-accelerated object detection\n        self.setup_gpu_detection()\n\n    def setup_gpu_detection(self):\n        \"\"\"Initialize GPU-accelerated object detection\"\"\"\n        # Load pre-trained model optimized for GPU\n        # Configure TensorRT for inference optimization\n        # Set up GPU memory for batch processing\n        pass\n\n    def image_callback(self, msg):\n        \"\"\"Process image and detect objects using GPU acceleration\"\"\"\n        try:\n            # Convert ROS image to OpenCV format\n            cv_image = self.bridge.imgmsg_to_cv2(msg, desired_encoding='bgr8')\n\n            # Run GPU-accelerated object detection\n            detections = self.gpu_detect_objects(cv_image)\n\n            # Publish detections\n            self.publish_detections(detections, msg.header)\n\n        except Exception as e:\n            self.get_logger().error(f'Error in object detection: {e}')\n\n    def gpu_detect_objects(self, image):\n        \"\"\"Perform GPU-accelerated object detection\"\"\"\n        # This would use Isaac ROS hardware-accelerated detection\n        # leveraging TensorRT and CUDA for:\n        # - YOLO inference\n        # - Classification networks\n        # - Feature extraction\n\n        # Placeholder for GPU detection results\n        detections = []\n\n        # Example detection result format\n        # In practice, this would come from GPU-accelerated inference\n        detection = {\n            'class': 'person',\n            'confidence': 0.95,\n            'bbox': [100, 100, 200, 200],  # [x, y, width, height]\n            'center': [150, 150]\n        }\n        detections.append(detection)\n\n        return detections\n\n    def publish_detections(self, detections, header):\n        \"\"\"Publish object detection results\"\"\"\n        detection_array = Detection2DArray()\n        detection_array.header = header\n\n        for detection in detections:\n            detection_msg = Detection2D()\n            detection_msg.header = header\n\n            # Set bounding box\n            detection_msg.bbox.center.x = detection['bbox'][0] + detection['bbox'][2] / 2\n            detection_msg.bbox.center.y = detection['bbox'][1] + detection['bbox'][3] / 2\n            detection_msg.bbox.size_x = detection['bbox'][2]\n            detection_msg.bbox.size_y = detection['bbox'][3]\n\n            # Set hypothesis\n            hypothesis = ObjectHypothesisWithPose()\n            hypothesis.hypothesis.class_id = detection['class']\n            hypothesis.hypothesis.score = detection['confidence']\n            detection_msg.results.append(hypothesis)\n\n            detection_array.detections.append(detection_msg)\n\n        self.detection_pub.publish(detection_array)\n\ndef main(args=None):\n    rclpy.init(args=args)\n    detector = IsaacROSObjectDetector()\n\n    try:\n        rclpy.spin(detector)\n    except KeyboardInterrupt:\n        detector.get_logger().info('Shutting down')\n    finally:\n        detector.destroy_node()\n        rclpy.shutdown()\n\nif __name__ == '__main__':\n    main()\n"})}),(0,i.jsx)(n.h2,{id:"integration-with-humanoid-robot-navigation",children:"Integration with Humanoid Robot Navigation"}),(0,i.jsx)(n.h3,{id:"complete-navigation-pipeline",children:"Complete Navigation Pipeline"}),(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'import rclpy\nfrom rclpy.node import Node\nfrom sensor_msgs.msg import Image, Imu, LaserScan\nfrom geometry_msgs.msg import Twist, PoseStamped\nfrom nav_msgs.msg import Odometry\nfrom tf2_ros import TransformBroadcaster\nimport numpy as np\n\nclass IsaacROSHumanoidNavigator(Node):\n    def __init__(self):\n        super().__init__(\'isaac_ros_humanoid_navigator\')\n\n        # Initialize all Isaac ROS components\n        self.initialize_perception_pipeline()\n        self.initialize_slam_system()\n        self.initialize_navigation_stack()\n        self.initialize_control_interface()\n\n        # TF broadcaster for transforms\n        self.tf_broadcaster = TransformBroadcaster(self)\n\n    def initialize_perception_pipeline(self):\n        """Initialize Isaac ROS perception pipeline"""\n        # Set up GPU-accelerated image processing\n        # Configure stereo vision\n        # Initialize object detection\n        pass\n\n    def initialize_slam_system(self):\n        """Initialize Isaac ROS SLAM system"""\n        # Set up visual-inertial SLAM\n        # Configure map building\n        # Initialize localization\n        pass\n\n    def initialize_navigation_stack(self):\n        """Initialize Isaac ROS navigation stack"""\n        # Set up path planning\n        # Configure obstacle avoidance\n        # Initialize trajectory generation\n        pass\n\n    def initialize_control_interface(self):\n        """Initialize interface to humanoid robot controllers"""\n        # Set up ROS 2 control interfaces\n        # Configure joint position/velocity commands\n        # Set up safety systems\n        pass\n\n    def navigate_to_goal(self, goal_pose):\n        """Navigate humanoid robot to specified goal"""\n        # Plan path using GPU-accelerated planners\n        path = self.plan_path_to_goal(goal_pose)\n\n        if path is not None:\n            # Execute navigation with safety checks\n            self.execute_navigation_path(path)\n\n    def plan_path_to_goal(self, goal_pose):\n        """Plan path to goal using Isaac ROS planners"""\n        # Use hardware-accelerated path planning\n        # Consider humanoid-specific constraints\n        # Optimize for bipedal locomotion\n        pass\n\n    def execute_navigation_path(self, path):\n        """Execute planned path with humanoid robot"""\n        # Generate footstep plans for bipedal navigation\n        # Execute walking controller\n        # Monitor safety and progress\n        pass\n\ndef main(args=None):\n    rclpy.init(args=args)\n    navigator = IsaacROSHumanoidNavigator()\n\n    try:\n        # Example: navigate to a goal\n        goal = PoseStamped()\n        goal.pose.position.x = 5.0\n        goal.pose.position.y = 3.0\n\n        navigator.navigate_to_goal(goal)\n\n        rclpy.spin(navigator)\n    except KeyboardInterrupt:\n        navigator.get_logger().info(\'Shutting down\')\n    finally:\n        navigator.destroy_node()\n        rclpy.shutdown()\n\nif __name__ == \'__main__\':\n    main()\n'})}),(0,i.jsx)(n.h2,{id:"performance-optimization",children:"Performance Optimization"}),(0,i.jsx)(n.h3,{id:"gpu-memory-management",children:"GPU Memory Management"}),(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'import rclpy\nfrom rclpy.node import Node\nimport cupy as cp  # Use CuPy for GPU memory management\nimport numpy as np\n\nclass IsaacROSGPUManager(Node):\n    def __init__(self):\n        super().__init__(\'isaac_ros_gpu_manager\')\n\n        # Initialize GPU memory pools\n        self.setup_gpu_memory_management()\n\n        # Monitor GPU usage\n        self.setup_gpu_monitoring()\n\n    def setup_gpu_memory_management(self):\n        """Set up GPU memory management for Isaac ROS"""\n        # Configure memory pools for different processing tasks\n        # Set up memory pre-allocation for real-time performance\n        # Configure CUDA streams for parallel processing\n\n        # Example: create GPU memory pools\n        self.image_processing_pool = cp.cuda.MemoryPool()\n        self.detection_pool = cp.cuda.MemoryPool()\n        self.planning_pool = cp.cuda.MemoryPool()\n\n        # Set memory pools as default\n        cp.cuda.set_allocator(self.image_processing_pool.malloc)\n\n    def setup_gpu_monitoring(self):\n        """Set up GPU usage monitoring"""\n        # Create timer to periodically check GPU usage\n        self.gpu_monitor_timer = self.create_timer(\n            1.0, self.monitor_gpu_usage)\n\n    def monitor_gpu_usage(self):\n        """Monitor GPU memory and utilization"""\n        try:\n            # Get GPU memory info\n            mem_info = cp.cuda.runtime.memGetInfo()\n            free_mem = mem_info[0]\n            total_mem = mem_info[1]\n            used_mem = total_mem - free_mem\n            mem_utilization = (used_mem / total_mem) * 100\n\n            # Log GPU usage\n            self.get_logger().info(\n                f\'GPU Memory - Used: {used_mem/1e9:.2f}GB, \'\n                f\'Total: {total_mem/1e9:.2f}GB, \'\n                f\'Utilization: {mem_utilization:.1f}%\'\n            )\n\n        except Exception as e:\n            self.get_logger().error(f\'Error monitoring GPU: {e}\')\n'})}),(0,i.jsx)(n.h2,{id:"best-practices-for-isaac-ros",children:"Best Practices for Isaac ROS"}),(0,i.jsx)(n.h3,{id:"1-hardware-optimization",children:"1. Hardware Optimization"}),(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Use compatible NVIDIA GPUs for maximum acceleration"}),"\n",(0,i.jsx)(n.li,{children:"Configure CUDA compute capability appropriately"}),"\n",(0,i.jsx)(n.li,{children:"Optimize GPU memory usage patterns"}),"\n",(0,i.jsx)(n.li,{children:"Use TensorRT for inference optimization"}),"\n"]}),(0,i.jsx)(n.h3,{id:"2-pipeline-design",children:"2. Pipeline Design"}),(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Structure processing pipelines for maximum parallelism"}),"\n",(0,i.jsx)(n.li,{children:"Use asynchronous processing where possible"}),"\n",(0,i.jsx)(n.li,{children:"Implement proper error handling and fallbacks"}),"\n",(0,i.jsx)(n.li,{children:"Design modular, reusable components"}),"\n"]}),(0,i.jsx)(n.h3,{id:"3-performance-monitoring",children:"3. Performance Monitoring"}),(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Monitor GPU utilization and memory usage"}),"\n",(0,i.jsx)(n.li,{children:"Profile algorithms for bottlenecks"}),"\n",(0,i.jsx)(n.li,{children:"Optimize data transfer between CPU and GPU"}),"\n",(0,i.jsx)(n.li,{children:"Use appropriate batch sizes for processing"}),"\n"]}),(0,i.jsx)(n.h3,{id:"4-integration-considerations",children:"4. Integration Considerations"}),(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Ensure compatibility with existing ROS 2 systems"}),"\n",(0,i.jsx)(n.li,{children:"Validate GPU-accelerated results against CPU implementations"}),"\n",(0,i.jsx)(n.li,{children:"Plan for graceful degradation when GPU is unavailable"}),"\n",(0,i.jsx)(n.li,{children:"Document hardware requirements clearly"}),"\n"]}),(0,i.jsx)(n.h2,{id:"troubleshooting-common-issues",children:"Troubleshooting Common Issues"}),(0,i.jsx)(n.h3,{id:"1-gpu-memory-issues",children:"1. GPU Memory Issues"}),(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# Check GPU memory usage\nnvidia-smi\n\n# Clear GPU memory cache\n# In Python: cp.get_default_memory_pool().free_all_blocks()\n"})}),(0,i.jsx)(n.h3,{id:"2-performance-optimization",children:"2. Performance Optimization"}),(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Use appropriate data types (float32 vs float64)"}),"\n",(0,i.jsx)(n.li,{children:"Minimize CPU-GPU data transfers"}),"\n",(0,i.jsx)(n.li,{children:"Use CUDA streams for overlapping operations"}),"\n",(0,i.jsx)(n.li,{children:"Optimize batch sizes for your hardware"}),"\n"]}),(0,i.jsx)(n.h3,{id:"3-compatibility-issues",children:"3. Compatibility Issues"}),(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Ensure CUDA versions match"}),"\n",(0,i.jsx)(n.li,{children:"Verify GPU compute capability"}),"\n",(0,i.jsx)(n.li,{children:"Check Isaac ROS package compatibility"}),"\n",(0,i.jsx)(n.li,{children:"Validate hardware acceleration is enabled"}),"\n"]}),(0,i.jsx)(n.h2,{id:"hands-on-exercise",children:"Hands-on Exercise"}),(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsx)(n.li,{children:"Install Isaac ROS packages in your development environment"}),"\n",(0,i.jsx)(n.li,{children:"Set up a GPU-accelerated image processing pipeline"}),"\n",(0,i.jsx)(n.li,{children:"Implement a basic GPU-accelerated path planning algorithm"}),"\n",(0,i.jsx)(n.li,{children:"Test performance improvements over CPU-only implementations"}),"\n",(0,i.jsx)(n.li,{children:"Validate results against traditional approaches"}),"\n"]}),(0,i.jsx)(n.h2,{id:"quiz-questions",children:"Quiz Questions"}),(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsx)(n.li,{children:"What are the key advantages of using Isaac ROS for hardware-accelerated navigation?"}),"\n",(0,i.jsx)(n.li,{children:"How does GPU acceleration improve performance in robot navigation tasks?"}),"\n",(0,i.jsx)(n.li,{children:"What are the best practices for optimizing Isaac ROS pipeline performance?"}),"\n"]})]})}function m(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(p,{...e})}):p(e)}},5959:(e,n,a)=>{a.d(n,{A:()=>d});var s=a(6540),i=a(4848);const t=({totalLessons:e,completedLessons:n,currentLesson:a="Current Lesson"})=>{const[t,o]=(0,s.useState)(0);return(0,s.useEffect)(()=>{const a=setTimeout(()=>{o(n/e*100)},300);return()=>clearTimeout(a)},[n,e]),(0,i.jsxs)("div",{className:"card padding--md margin-bottom--lg",children:[(0,i.jsxs)("div",{className:"row",children:[(0,i.jsxs)("div",{className:"col col--8",children:[(0,i.jsx)("h3",{children:"Learning Progress"}),(0,i.jsxs)("p",{children:["Currently studying: ",(0,i.jsx)("strong",{children:a})]})]}),(0,i.jsx)("div",{className:"col col--4 text--right",children:(0,i.jsxs)("span",{className:"badge badge--primary",children:[Math.round(t),"% Complete"]})})]}),(0,i.jsxs)("div",{className:"margin-top--md",children:[(0,i.jsx)("div",{className:"progress-indicator",children:(0,i.jsx)("div",{className:"progress-bar",style:{width:`${t}%`,transition:"width 1s ease-in-out"}})}),(0,i.jsx)("div",{className:"margin-top--sm",children:(0,i.jsxs)("small",{children:[n," of ",e," lessons completed"]})})]}),(0,i.jsxs)("div",{className:"margin-top--md",children:[(0,i.jsx)("button",{className:"button button--primary button--sm margin-right--sm",onClick:()=>alert("Lesson marked as completed!"),children:"\u2713 Mark Complete"}),(0,i.jsx)("button",{className:"button button--secondary button--sm",onClick:()=>alert("Lesson bookmarked!"),children:"\u2605 Bookmark"})]})]})},o=({title:e,questions:n})=>{const[a,t]=(0,s.useState)(Array(n.length).fill(null)),[o,r]=(0,s.useState)(!1),[l,c]=(0,s.useState)(!1),d=n.reduce((e,n,s)=>a[s]===n.correctAnswer?e+1:e,0);return(0,i.jsxs)("div",{className:"card padding--md margin-bottom--lg",children:[(0,i.jsx)("h3",{children:e}),n.map((e,n)=>(0,i.jsxs)("div",{className:"margin-bottom--md",children:[(0,i.jsxs)("h4",{children:["Question ",n+1,": ",e.question]}),(0,i.jsx)("div",{className:"margin-left--md",children:e.options.map((e,s)=>(0,i.jsx)("div",{className:"margin-bottom--sm",children:(0,i.jsxs)("label",{style:{display:"flex",alignItems:"center"},children:[(0,i.jsx)("input",{type:"radio",name:`question-${n}`,checked:a[n]===s,onChange:()=>((e,n)=>{if(l)return;const s=[...a];s[e]=n,t(s)})(n,s),disabled:l,style:{marginRight:"0.5rem"}}),e]})},s))}),o&&(0,i.jsx)("div",{className:"margin-top--sm padding--sm "+(a[n]===e.correctAnswer?"alert alert--success":"alert alert--danger"),children:a[n]===e.correctAnswer?(0,i.jsx)("p",{children:(0,i.jsx)("strong",{children:"\u2713 Correct!"})}):null!==a[n]?(0,i.jsxs)("p",{children:[(0,i.jsx)("strong",{children:"\u2717 Incorrect."})," Correct answer: ",e.options[e.correctAnswer],(0,i.jsx)("br",{}),(0,i.jsx)("small",{children:e.explanation})]}):(0,i.jsx)("p",{children:(0,i.jsx)("small",{children:e.explanation})})})]},e.id)),l?(0,i.jsxs)("div",{children:[(0,i.jsxs)("div",{className:"alert alert--success margin-bottom--md",children:[(0,i.jsxs)("h4",{children:["Quiz Results: ",d,"/",n.length," correct"]}),(0,i.jsxs)("p",{children:["You scored ",Math.round(d/n.length*100),"%!"]})]}),(0,i.jsx)("button",{className:"button button--secondary",onClick:()=>{t(Array(n.length).fill(null)),r(!1),c(!1)},children:"Try Again"})]}):(0,i.jsx)("button",{className:"button button--primary",onClick:()=>{c(!0),r(!0)},children:"Submit Quiz"})]})},r=[{id:1,question:"What does ROS stand for?",options:["Robot Operating System","Robotics Operating Software","Remote Operating System","Robotic Operation Suite"],correctAnswer:0,explanation:"ROS stands for Robot Operating System, a flexible framework for writing robot software."},{id:2,question:"Which of the following is a core concept in ROS 2?",options:["Nodes and Topics","Classes and Objects","Functions and Variables","Databases and Tables"],correctAnswer:0,explanation:"Nodes and Topics are fundamental concepts in ROS 2 for communication between different parts of a robot system."}],l=()=>(0,i.jsx)(o,{title:"ROS 2 Fundamentals Quiz",questions:r});var c=a(8774);const d=({children:e,title:n="Lesson",chapter:a=1,lesson:s=1})=>{const o=s>1?s-1:null,r=s<3?s+1:null,d=`/docs/chapter${a}`,p=(e,n)=>{if(1===e){if(1===n)return"spec-kit-plus-workflow";if(2===n)return"physical-ai-embodied-intelligence";if(3===n)return"development-environment-setup"}else if(2===e){if(1===n)return"ros2-architecture";if(2===n)return"humanoid-robot-modeling";if(3===n)return"bridging-ai-agents"}else if(3===e){if(1===n)return"gazebo-environment-setup";if(2===n)return"simulating-physics-collisions";if(3===n)return"sensor-simulation"}else if(4===e){if(1===n)return"isaac-sim-synthetic-data";if(2===n)return"hardware-accelerated-navigation";if(3===n)return"bipedal-path-planning"}else if(5===e){if(1===n)return"voice-to-action";if(2===n)return"cognitive-planning";if(3===n)return"capstone-project-execution"}return"spec-kit-plus-workflow"};p(a,s);return(0,i.jsxs)("div",{className:"interactive-lesson",children:[(0,i.jsxs)("div",{className:"chapter-header margin-bottom--lg",children:[(0,i.jsxs)("span",{className:"chapter-indicator",children:["Chapter ",a," \u2022 Lesson ",s]}),(0,i.jsx)("h1",{children:n})]}),(0,i.jsx)(t,{totalLessons:3,completedLessons:s-1,currentLesson:n}),(0,i.jsx)("div",{className:"lesson-content",children:e}),(0,i.jsxs)("div",{className:"margin-top--xl",children:[(0,i.jsx)("h3",{children:"Knowledge Check"}),(0,i.jsx)(l,{})]}),(0,i.jsx)("div",{className:"margin-top--lg",children:(0,i.jsxs)("div",{className:"row",children:[(0,i.jsx)("div",{className:"col col--6",children:o&&(0,i.jsx)(c.A,{to:`${d}/lesson${o}/${p(a,o)}`,className:"button button--secondary",children:"\u2190 Previous Lesson"})}),(0,i.jsx)("div",{className:"col col--6 text--right",children:r&&(0,i.jsx)(c.A,{to:`${d}/lesson${r}/${p(a,r)}`,className:"button button--primary",children:"Next Lesson \u2192"})})]})}),(0,i.jsxs)("div",{className:"margin-top--lg interactive-controls-container",children:[(0,i.jsx)("button",{className:"personalize-button",onClick:()=>alert("Content personalized!"),children:"\ud83c\udfaf Personalize Learning"}),(0,i.jsx)("button",{className:"translate-button",onClick:()=>alert("Content translated to Urdu!"),children:"\ud83c\udf10 Translate to Urdu"})]})]})}},8453:(e,n,a)=>{a.d(n,{R:()=>o,x:()=>r});var s=a(6540);const i={},t=s.createContext(i);function o(e){const n=s.useContext(t);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function r(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:o(e.components),s.createElement(t.Provider,{value:n},e.children)}}}]);